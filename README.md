ðŸŽ§Pronunciation Trainer Backend (Django + DRF)

Backend for a web app that helps users practice pronunciation by sending **reference text + recorded audio** and receiving:
- `recognizedText` (STT output)
- `mispronouncedWords` (comparison result)
- optional `correctionClips` (TTS mp3 for wrong words)

## What was implemented (Backend)
- âœ… `POST /api/audio/process/` (upload text + wav, run local STT + compare, return JSON)
- âœ… WAV validation: must be real WAV, **mono**, **16000 Hz**
- âœ… Optional paid TTS via Yandex (disabled by default, controlled by `enable_tts`)
- âœ… Secure mp3 download endpoint: `GET /api/audio/corrections/<taskId>/<filename>`
- âœ… Caching to avoid repeated runs for same (audio + text)
- âœ… Cleanup command: `python manage.py cleanup_audio`

---

## Run locally (Windows / CMD)

### 1) Create venv + install
```bat
cd backend
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Vosk model (Required)
Place Vosk model folder here:
```
backend/AI/model/
```
It must contain folders like: `am/ conf/ graph/ ivector/`.

### 3) Migrate + run
```bat
python manage.py migrate
python manage.py runserver
```

---

## API (Quick)

### POST /api/audio/process/
**multipart/form-data**
- `text` (required)
- `audio` (required WAV: mono, 16000 Hz)
- `enable_tts` (optional, default: false)

Example (safe, no TTS):
```bat
curl -X POST "http://127.0.0.1:8000/api/audio/process/" ^
  -F "text=I love my family." ^
  -F "enable_tts=false" ^
  -F "audio=@C:\path\to\input.wav;type=audio/wav"
```

Response:
```json
{
  "taskId": "uuid",
  "recognizedText": "...",
  "mispronouncedWords": ["..."],
  "correctionClips": [
    {"word":"...", "file":"1_word.mp3", "url":"/api/audio/corrections/<taskId>/1_word.mp3"}
  ]
}
```

### GET /api/audio/corrections/<taskId>/<filename>
Streams mp3 generated by TTS.

---

## Optional: Enable TTS (Paid)
TTS is paid and must be enabled only on-demand.

Set env vars (Windows CMD):
```bat
setx YANDEX_API_KEY "YOUR_KEY"
setx YANDEX_FOLDER_ID "YOUR_FOLDER_ID"
```
Restart the server after setting variables.

---

## Frontend integration map (step-by-step)

1) **Get reference text**
   - User chooses a text (or you already have it on the page).

2) **Record audio in browser**
   - Record voice using MediaRecorder.

3) **Ensure audio format**
   - Backend accepts **WAV mono 16000 Hz**.
   - If the browser produces webm/ogg, convert to WAV 16k mono on frontend OR via a dedicated conversion step.

4) **Send request**
   - `POST /api/audio/process/` as `multipart/form-data`
   - Fields: `text`, `audio`, optional `enable_tts`
   - Default `enable_tts=false` (cost-safe)

5) **Render results**
   - Use `mispronouncedWords` to highlight words in the displayed text.
   - Show `recognizedText` for debugging/feedback.

6) **Audio feedback (if enabled)**
   - If `correctionClips` is not empty:
     - For each clip: play `http://127.0.0.1:8000` + `clip.url` in an `<audio>` element.

7) **Repeat flow**
   - Re-run analysis only when user clicks â€œAnalyzeâ€ (avoid frequent paid calls).
   - Keep TTS off during development/testing.

8) **Handle errors**
   - Missing fields -> 400
   - Wrong WAV format -> 400: `audio must be a valid WAV (mono, 16000 Hz)`
